# ============================================================================
# Prometheus Configuration for AI-SOC (Host + Docker Hybrid)
# ============================================================================

global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s
  external_labels:
    cluster: "ai-soc"
    environment: "production"

# ============================================================================
# Scrape Configurations
# ============================================================================
scrape_configs:

  # --------------------------------------------------------------------------
  # Prometheus Self-Monitoring
  # --------------------------------------------------------------------------
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
        labels:
          component: "monitoring"
          service: "prometheus"

  # --------------------------------------------------------------------------
  # CrewAI Orchestrator (FastAPI + Prometheus metrics)
  # --------------------------------------------------------------------------
  - job_name: "crewai-orchestrator"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "host.docker.internal:8002"
        labels:
          component: "ai-services"
          service: "crewai-orchestrator"

  # --------------------------------------------------------------------------
  # Alert Triage Service
  # Container: alert-triage → 8100 -> 8000
  # --------------------------------------------------------------------------
  - job_name: "alert-triage"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "host.docker.internal:8100"
        labels:
          component: "ai-services"
          service: "alert-triage"

  # --------------------------------------------------------------------------
  # IDS / ML Inference Service
  # Container: ids-inference → 8500 -> 8000
  # --------------------------------------------------------------------------
  - job_name: "ml-inference"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "host.docker.internal:8500"
        labels:
          component: "ai-services"
          service: "ml-inference"

  # --------------------------------------------------------------------------
  # RAG Service
  # Container: rag-service → 8001 -> 8000
  # --------------------------------------------------------------------------
  - job_name: "rag-service"
    metrics_path: "/metrics"
    static_configs:
      - targets:
          - "host.docker.internal:8001"
        labels:
          component: "ai-services"
          service: "rag-service"

  # --------------------------------------------------------------------------
  # ChromaDB
  # Container: chromadb → 8000
  # --------------------------------------------------------------------------
  - job_name: "chromadb"
    metrics_path: "/api/v1/metrics"
    static_configs:
      - targets:
          - "host.docker.internal:8000"
        labels:
          component: "ai-services"
          service: "chromadb"

  # --------------------------------------------------------------------------
  # Ollama LLM Runtime
  # Container: ollama → 11434
  # --------------------------------------------------------------------------
  - job_name: "ollama"
    metrics_path: "/api/metrics"
    static_configs:
      - targets:
          - "host.docker.internal:11434"
        labels:
          component: "ai-services"
          service: "ollama"

  # --------------------------------------------------------------------------
  # Docker Engine Metrics (ONLY if enabled)
  # --------------------------------------------------------------------------
  - job_name: "docker-engine"
    static_configs:
      - targets:
          - "host.docker.internal:9323"
        labels:
          component: "infrastructure"
          service: "docker-engine"
